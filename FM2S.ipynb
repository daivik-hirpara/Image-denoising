{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3ZtVXdscwmx",
        "outputId": "ceb6387d-8f88-48fd-f031-41de0b9a7310"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (11.2.1)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.5.10)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (24.2)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops scikit-image opencv-python-headless tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from scipy import ndimage as nd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange\n",
        "from tqdm import tqdm\n"
      ],
      "metadata": {
        "id": "csB4pzPLc55k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFOCAL_CONFIG = {'n_chan': 2, 'stride': 75, 'g_map': 200, 'p_map': 30, 'lam_p': 70, 'w_size': 3}\n",
        "TWOPHOTON_CONFIG = {'n_chan': 2, 'stride': 75, 'g_map': 175, 'p_map': 30, 'lam_p': 60, 'w_size': 3}\n",
        "WIDEFIELD_CONFIG = {'n_chan': 1, 'stride': 75, 'g_map': 220, 'p_map': 45, 'lam_p': 2000, 'w_size': 11}\n",
        "BASE_CONFIG = {'n_chan': 6, 'stride': 5, 'g_map': 60, 'p_map': 30, 'lam_p': 150, 'w_size': 3}\n",
        "\n",
        "def config_map(config):\n",
        "    config = config.lower()\n",
        "    if config == 'confocal':\n",
        "        return CONFOCAL_CONFIG\n",
        "    elif config == 'twophoton':\n",
        "        return TWOPHOTON_CONFIG\n",
        "    elif config == 'widefield':\n",
        "        return WIDEFIELD_CONFIG\n",
        "    else:\n",
        "        return BASE_CONFIG\n"
      ],
      "metadata": {
        "id": "tFHRBITPc83c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 3407\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.get_device_name())\n",
        "train_num = 450\n",
        "max_epoch = 5\n",
        "\n",
        "class network(nn.Module):\n",
        "    def __init__(self, n_chan):\n",
        "        super(network, self).__init__()\n",
        "        self.act = nn.LeakyReLU(negative_slope=1e-3)\n",
        "        self.conv1 = nn.Conv2d(n_chan, 24, 5, padding=2)\n",
        "        self.conv2 = nn.Conv2d(24, 12, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(12, n_chan, 5, padding=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.act(self.conv1(x))\n",
        "        x = self.act(self.conv2(x))\n",
        "        x = self.conv3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEXjsrZRc9P7",
        "outputId": "baba2f00-54da-4604-c1d8-cb78eb25268c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def noise_addition(img, config):\n",
        "    B, C, H, W = img.shape\n",
        "    stride = config['stride']\n",
        "    new_H = ((H + stride - 1) // stride) * stride\n",
        "    new_W = ((W + stride - 1) // stride) * stride\n",
        "    pad_h = new_H - H\n",
        "    pad_w = new_W - W\n",
        "\n",
        "    img_padded = F.pad(img, (0, pad_w, 0, pad_h), mode='constant', value=0)\n",
        "    patches = img_padded.unfold(2, stride, stride).unfold(3, stride, stride)\n",
        "    noise_idx = patches.mean(dim=(1, 4, 5)).clamp(1e-5, 0.15)\n",
        "    gaussian_level = config['g_map'] * noise_idx\n",
        "    poisson_level = config['p_map'] / noise_idx\n",
        "\n",
        "    gaussian_level_exp = rearrange(gaussian_level, 'b n_h n_w -> b 1 n_h n_w 1 1')\n",
        "    poisson_level_exp = rearrange(poisson_level, 'b n_h n_w -> b 1 n_h n_w 1 1')\n",
        "\n",
        "    patches_noisy = torch.poisson(patches * poisson_level_exp) / poisson_level_exp\n",
        "    gaussian_noise = torch.normal(mean=torch.zeros_like(patches_noisy), std=(gaussian_level_exp / 255))\n",
        "    patches_noisy = patches_noisy + gaussian_noise\n",
        "    patches_noisy = torch.clamp(patches_noisy, 0, 1)\n",
        "\n",
        "    noisy_img_padded = rearrange(patches_noisy, 'b c n_h n_w new_h new_w -> b c (n_h new_h) (n_w new_w)')\n",
        "    noisy_img = noisy_img_padded[:, :, :H, :W]\n",
        "    noisy_img = torch.poisson(noisy_img * config['lam_p']) / config['lam_p']\n",
        "    noisy_img = torch.clamp(noisy_img, 0, 1)\n",
        "\n",
        "    return noisy_img\n"
      ],
      "metadata": {
        "id": "roBewAJgc_Yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FM2S(raw_noisy_img, config: dict):\n",
        "    raw_noisy_img = raw_noisy_img / 255\n",
        "    clean_img = nd.median_filter(raw_noisy_img, config['w_size'])\n",
        "\n",
        "    clean_img = torch.tensor(clean_img, dtype=torch.float32, device=device).unsqueeze(0).repeat(1, config['n_chan'], 1, 1)\n",
        "    raw_noisy_img = torch.tensor(raw_noisy_img, dtype=torch.float32, device=device).unsqueeze(0).repeat(1, config['n_chan'], 1, 1)\n",
        "\n",
        "    model = network(config['n_chan']).to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(5):\n",
        "        pred = model(raw_noisy_img)\n",
        "        loss = criterion(pred, clean_img)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    for _ in tqdm(range(train_num), desc=\"Training\"):\n",
        "        noisy_img = noise_addition(clean_img, config)\n",
        "        for _ in range(max_epoch):\n",
        "            pred = model(noisy_img)\n",
        "            loss = criterion(pred, clean_img)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        denoised_img = model(raw_noisy_img)\n",
        "\n",
        "    denoised_img = torch.clamp(denoised_img, 0, 1) * 255\n",
        "    denoised_img = torch.mean(denoised_img, dim=1).squeeze()\n",
        "    denoised_img = denoised_img.cpu().int().numpy()\n",
        "\n",
        "    return denoised_img\n"
      ],
      "metadata": {
        "id": "ksNHCDQVdBVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = \"001_2.png\"\n",
        "output_path = \"output_image001b.png\"\n",
        "config_name = \"confocal\"  # or 'twophoton', 'widefield', 'base'\n",
        "\n",
        "raw = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
        "config = config_map(config_name)\n",
        "result = FM2S(raw, config)\n",
        "cv2.imwrite(output_path, result)\n",
        "print(\"Denoising completed and saved to\", output_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWHXTPnLdEil",
        "outputId": "e6373f12-89c4-4f0d-8971-32162d3a7b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 450/450 [00:32<00:00, 13.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Denoising completed and saved to output_image001b.png\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vu1bA_qRuB-j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6znqyZyfkuz",
        "outputId": "9d4d73d3-92a2-4281-f371-b1207564825a"
      },
      "outputs": [],
      "source": [
        "# Self-Supervised Reinforcement Learning for Single Image Denoising\n",
        "# S2SRL-Denoise: Combining Self2Self+ with RL and Partial Convolution U-Net for CVPR submission\n",
        "# Input: Single noisy RGB image | Output: Denoised image\n",
        "# No ground truth required - fully self-supervised using NR-IQA rewards\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Install required packages for Colab\n",
        "# !pip install torch torchvision opencv-python pyiqa\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class PartialConv2d(nn.Module):\n",
        "    \"\"\"\n",
        "    Partial Convolution Layer\n",
        "    Reference: \"Image Inpainting for Irregular Holes Using Partial Convolutions\"\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
        "                 padding=0, dilation=1, groups=1, bias=True):\n",
        "        super(PartialConv2d, self).__init__()\n",
        "\n",
        "        self.input_conv = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
        "                                   stride, padding, dilation, groups, bias)\n",
        "        self.mask_conv = nn.Conv2d(in_channels, out_channels, kernel_size,\n",
        "                                  stride, padding, dilation, groups, False)\n",
        "\n",
        "        # Initialize mask convolution with ones\n",
        "        nn.init.constant_(self.mask_conv.weight, 1.0)\n",
        "\n",
        "        # Freeze mask convolution parameters\n",
        "        for param in self.mask_conv.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, input_tensor, mask_tensor):\n",
        "        # Apply convolutions\n",
        "        output = self.input_conv(input_tensor * mask_tensor)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output_mask = self.mask_conv(mask_tensor)\n",
        "\n",
        "        # Calculate normalization\n",
        "        no_update_holes = output_mask == 0\n",
        "        mask_sum = output_mask.masked_fill_(no_update_holes, 1.0)\n",
        "\n",
        "        output_pre = output / mask_sum\n",
        "        output = output_pre.masked_fill_(no_update_holes, 0.0)\n",
        "\n",
        "        new_mask = torch.ones_like(output)\n",
        "        new_mask = new_mask.masked_fill_(no_update_holes, 0.0)\n",
        "\n",
        "        return output, new_mask\n",
        "\n",
        "class PConvBNReLU(nn.Module):\n",
        "    \"\"\"Partial Convolution + BatchNorm + ReLU block\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
        "        super(PConvBNReLU, self).__init__()\n",
        "        self.pconv = PartialConv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, input_tensor, mask_tensor):\n",
        "        x, mask = self.pconv(input_tensor, mask_tensor)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        return x, mask\n",
        "\n",
        "class ConvBNReLU(nn.Module):\n",
        "    \"\"\"Standard Convolution + BatchNorm + ReLU block for decoder\"\"\"\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1, dropout_p=0.0):\n",
        "        super(ConvBNReLU, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout2d(dropout_p) if dropout_p > 0 else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        if self.dropout is not None:\n",
        "            x = self.dropout(x)\n",
        "        return x\n",
        "\n",
        "class PartialConvUNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Enhanced Partial Convolution U-Net for Self-Supervised Denoising\n",
        "    Based on the provided architecture with improvements for denoising\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3, out_channels=3, base_features=48):\n",
        "        super(PartialConvUNet, self).__init__()\n",
        "\n",
        "        # Encoder with Partial Convolutions\n",
        "        self.enc_conv0 = PConvBNReLU(in_channels, base_features)\n",
        "        self.enc_conv1 = PConvBNReLU(base_features, base_features)\n",
        "\n",
        "        self.enc_conv2 = PConvBNReLU(base_features, base_features)\n",
        "        self.enc_conv3 = PConvBNReLU(base_features, base_features)\n",
        "        self.enc_conv4 = PConvBNReLU(base_features, base_features)\n",
        "        self.enc_conv5 = PConvBNReLU(base_features, base_features)\n",
        "        self.enc_conv6 = PConvBNReLU(base_features, base_features)\n",
        "\n",
        "        # Decoder with Standard Convolutions - Fixed channel dimensions\n",
        "        # Corrected input channels based on intended skip connections + upsampled\n",
        "        self.dec_conv5 = ConvBNReLU(base_features * 2, base_features)  # 48 (upsampled) + 48 (skip) -> 48\n",
        "        self.dec_conv5b = ConvBNReLU(base_features, base_features)     # 48 -> 48\n",
        "\n",
        "        self.dec_conv4 = ConvBNReLU(base_features * 2, base_features)  # 48 + 48 -> 48\n",
        "        self.dec_conv4b = ConvBNReLU(base_features, base_features)     # 48 -> 48\n",
        "\n",
        "        self.dec_conv3 = ConvBNReLU(base_features * 2, base_features)  # 48 + 48 -> 48\n",
        "        self.dec_conv3b = ConvBNReLU(base_features, base_features)     # 48 -> 48\n",
        "\n",
        "        self.dec_conv2 = ConvBNReLU(base_features * 2, base_features)  # 48 + 48 -> 48\n",
        "        self.dec_conv2b = ConvBNReLU(base_features, base_features)     # 48 -> 48\n",
        "\n",
        "        # Final decoder layer should concatenate with the very first encoder output\n",
        "        # FIX: Change input channels from base_features + in_channels (51) to base_features * 2 (96)\n",
        "        # as it concatenates with the skip connection from enc_conv1 which has base_features channels.\n",
        "        self.dec_conv1a = ConvBNReLU(base_features * 2, 32) # 48 (upsampled) + 48 (skip from enc_conv1) -> 32\n",
        "        self.dec_conv1b = ConvBNReLU(32, 16)                           # 32 -> 16\n",
        "        self.dec_conv1 = nn.Conv2d(16, out_channels, kernel_size=3, padding=1)  # 16 -> 3\n",
        "\n",
        "        # Pooling and upsampling\n",
        "        self.maxpool = nn.MaxPool2d(2, 2)\n",
        "        # Using F.interpolate instead of nn.Upsample for potentially better results and direct size/scale control\n",
        "        # self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # If no mask provided, create a full mask\n",
        "        if mask is None:\n",
        "            mask = torch.ones_like(x)\n",
        "\n",
        "        # Store input for residual connection\n",
        "        residual = x\n",
        "\n",
        "        # Encoder path with skip connections\n",
        "        skips = [] # Store outputs *before* pooling\n",
        "\n",
        "        # Level 0\n",
        "        n, mask = self.enc_conv0(x, mask)\n",
        "        n, mask = self.enc_conv1(n, mask)\n",
        "        skips.append(n) # Append *before* pooling (Output of enc_conv1, base_features channels)\n",
        "        n = self.maxpool(n)\n",
        "        mask = self.maxpool(mask)\n",
        "\n",
        "\n",
        "        # Level 1\n",
        "        n, mask = self.enc_conv2(n, mask)\n",
        "        skips.append(n) # Append *before* pooling (Output of enc_conv2, base_features channels)\n",
        "        n = self.maxpool(n)\n",
        "        mask = self.maxpool(mask)\n",
        "\n",
        "\n",
        "        # Level 2\n",
        "        n, mask = self.enc_conv3(n, mask)\n",
        "        skips.append(n) # Append *before* pooling (Output of enc_conv3, base_features channels)\n",
        "        n = self.maxpool(n)\n",
        "        mask = self.maxpool(mask)\n",
        "\n",
        "\n",
        "        # Level 3\n",
        "        n, mask = self.enc_conv4(n, mask)\n",
        "        skips.append(n) # Append *before* pooling (Output of enc_conv4, base_features channels)\n",
        "        n = self.maxpool(n)\n",
        "        mask = self.maxpool(mask)\n",
        "\n",
        "\n",
        "        # Level 4\n",
        "        n, mask = self.enc_conv5(n, mask)\n",
        "        skips.append(n) # Append *before* pooling (Output of enc_conv5, base_features channels)\n",
        "        n = self.maxpool(n)\n",
        "        mask = self.maxpool(mask)\n",
        "\n",
        "        # Bottleneck\n",
        "        n, mask = self.enc_conv6(n, mask)\n",
        "\n",
        "        # Decoder path - Upsample and concatenate with corresponding skip connection\n",
        "        # Using F.interpolate for upsampling and matching size\n",
        "        n = F.interpolate(n, scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        # Pop skip connection from the last encoder level (Level 4) - 48 channels\n",
        "        n = torch.cat([n, skips.pop()], dim=1) # 48 (upsampled) + 48 (skip) = 96 channels\n",
        "        n = self.dec_conv5(n) # Input 96, output 48\n",
        "        n = self.dec_conv5b(n) # Input 48, output 48\n",
        "\n",
        "        n = F.interpolate(n, scale_factor=2, mode='bilinear', align_corners=True) # 48 channels upsampled\n",
        "        # Pop skip connection from Level 3 - 48 channels\n",
        "        n = torch.cat([n, skips.pop()], dim=1) # 48 + 48 = 96 channels\n",
        "        n = self.dec_conv4(n) # Input 96, output 48\n",
        "        n = self.dec_conv4b(n) # Input 48, output 48\n",
        "\n",
        "        n = F.interpolate(n, scale_factor=2, mode='bilinear', align_corners=True) # 48 channels upsampled\n",
        "        # Pop skip connection from Level 2 - 48 channels\n",
        "        n = torch.cat([n, skips.pop()], dim=1) # 48 + 48 = 96 channels\n",
        "        n = self.dec_conv3(n) # Input 96, output 48\n",
        "        n = self.dec_conv3b(n) # Input 48, output 48\n",
        "\n",
        "        n = F.interpolate(n, scale_factor=2, mode='bilinear', align_corners=True) # 48 channels upsampled\n",
        "        # Pop skip connection from Level 1 - 48 channels\n",
        "        n = torch.cat([n, skips.pop()], dim=1) # 48 + 48 = 96 channels\n",
        "        n = self.dec_conv2(n) # Input 96, output 48\n",
        "        n = self.dec_conv2b(n) # Input 48, output 48\n",
        "\n",
        "        n = F.interpolate(n, scale_factor=2, mode='bilinear', align_corners=True) # 48 channels upsampled\n",
        "        # Pop skip connection from Level 0 - 48 channels (Output of enc_conv1 before pooling)\n",
        "        # Concatenate upsampled features (48) with the skip connection from Level 0 (48)\n",
        "        n = torch.cat([n, skips.pop()], dim=1) # 48 + 48 = 96 channels\n",
        "        # This should match the input channels expected by dec_conv1a\n",
        "        n = self.dec_conv1a(n) # Input 96, output 32\n",
        "        n = self.dec_conv1b(n) # Input 32, output 16\n",
        "        n = self.dec_conv1(n) # Input 16, output 3\n",
        "\n",
        "        # Global residual connection\n",
        "        return n + residual\n",
        "\n",
        "\n",
        "class PyIQAQualityAssessment:\n",
        "    \"\"\"\n",
        "    Professional No-Reference Image Quality Assessment using PyIQA library\n",
        "    Supports multiple state-of-the-art NR-IQA models including PAQ2PIQ, NIQE, BRISQUE, etc.\n",
        "    \"\"\"\n",
        "    def __init__(self, metric_names=['paq2piq', 'niqe', 'brisque'], device=None):\n",
        "        \"\"\"\n",
        "        Initialize PyIQA metrics\n",
        "\n",
        "        Args:\n",
        "            metric_names: List of metric names to use. Available:\n",
        "                         'paq2piq', 'niqe', 'brisque', 'nima', 'dbcnn', 'musiq', etc.\n",
        "            device: torch device\n",
        "        \"\"\"\n",
        "        import pyiqa\n",
        "\n",
        "        self.device = device if device is not None else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.metrics = {}\n",
        "        self.metric_names = metric_names\n",
        "\n",
        "        print(\"Initializing PyIQA metrics...\")\n",
        "        for metric_name in metric_names:\n",
        "            try:\n",
        "                # Create metric with pretrained weights\n",
        "                metric = pyiqa.create_metric(metric_name, device=self.device)\n",
        "                self.metrics[metric_name] = metric\n",
        "                print(f\"✓ Loaded {metric_name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"✗ Failed to load {metric_name}: {e}\")\n",
        "\n",
        "        if not self.metrics:\n",
        "            raise RuntimeError(\"No metrics could be loaded. Please check pyiqa installation.\")\n",
        "\n",
        "    def compute_score(self, img_tensor):\n",
        "        \"\"\"\n",
        "        Compute composite no-reference quality score using multiple metrics\n",
        "\n",
        "        Args:\n",
        "            img_tensor: Tensor of shape [1, 3, H, W] with values in [0, 1]\n",
        "\n",
        "        Returns:\n",
        "            composite_score: Higher score indicates better quality\n",
        "        \"\"\"\n",
        "        scores = {}\n",
        "\n",
        "        # Ensure input is properly formatted for PyIQA\n",
        "        if img_tensor.dim() == 3:\n",
        "            img_tensor = img_tensor.unsqueeze(0)\n",
        "\n",
        "        # Clamp values to [0, 1] range\n",
        "        img_tensor = torch.clamp(img_tensor, 0, 1)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for name, metric in self.metrics.items():\n",
        "                try:\n",
        "                    score = metric(img_tensor)\n",
        "                    if isinstance(score, torch.Tensor):\n",
        "                        score = score.item()\n",
        "                    scores[name] = score\n",
        "                    print(f\"  {name}: {score:.4f}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"  Error computing {name}: {e}\")\n",
        "                    scores[name] = 0.0\n",
        "\n",
        "        # Compute composite score\n",
        "        # Different metrics have different scales and directions\n",
        "        composite_score = 0.0\n",
        "        weight_sum = 0.0\n",
        "\n",
        "        # PAQ2PIQ: higher is better (0-100 scale typically)\n",
        "        if 'paq2piq' in scores:\n",
        "            composite_score += scores['paq2piq'] * 0.5\n",
        "            weight_sum += 0.5\n",
        "\n",
        "        # NIQE: lower is better, so we invert it\n",
        "        if 'niqe' in scores:\n",
        "            niqe_score = max(0, 20 - scores['niqe'])  # Invert and normalize\n",
        "            composite_score += niqe_score * 0.3\n",
        "            weight_sum += 0.3\n",
        "\n",
        "        # BRISQUE: lower is better, so we invert it\n",
        "        if 'brisque' in scores:\n",
        "            brisque_score = max(0, 100 - scores['brisque'])  # Invert and normalize\n",
        "            composite_score += brisque_score * 0.2\n",
        "            weight_sum += 0.2\n",
        "\n",
        "        # Normalize by total weight\n",
        "        if weight_sum > 0:\n",
        "            composite_score /= weight_sum\n",
        "\n",
        "        return composite_score\n",
        "\n",
        "class RLAgent:\n",
        "    \"\"\"\n",
        "    Reinforcement Learning agent for optimizing denoising parameters\n",
        "    Uses policy gradient (REINFORCE) to learn optimal masking strategies and parameters\n",
        "    \"\"\"\n",
        "    def __init__(self, action_space_size=9, lr=0.02):\n",
        "        self.action_space_size = action_space_size\n",
        "        # Actions: [mask_prob_low, mask_prob_med, mask_prob_high] x [bernoulli, structured, gradient]\n",
        "        self.mask_probs = [0.2, 0.5, 0.8]\n",
        "        self.mask_strategies = ['bernoulli','bernoulli','bernoulli']\n",
        "        self.actions = [(p, s) for p in self.mask_probs for s in self.mask_strategies]\n",
        "\n",
        "        # Policy network (simple linear layer for discrete actions)\n",
        "        self.policy_logits = torch.zeros(action_space_size, requires_grad=True, device=device)\n",
        "        self.optimizer = optim.Adam([self.policy_logits], lr=lr)\n",
        "\n",
        "        # Experience storage\n",
        "        self.log_probs = []\n",
        "        self.rewards = []\n",
        "\n",
        "    def select_action(self):\n",
        "        \"\"\"Select action using current policy\"\"\"\n",
        "        probs = torch.softmax(self.policy_logits, dim=0)\n",
        "        m = torch.distributions.Categorical(probs)\n",
        "        action = m.sample()\n",
        "        self.log_probs.append(m.log_prob(action))\n",
        "        mask_prob, mask_strategy = self.actions[action.item()]\n",
        "        return mask_prob, mask_strategy, action.item()\n",
        "\n",
        "    def update_policy(self):\n",
        "        \"\"\"Update policy using REINFORCE\"\"\"\n",
        "        if len(self.rewards) == 0:\n",
        "            return\n",
        "\n",
        "        # Normalize rewards\n",
        "        rewards = torch.tensor(self.rewards, device=device)\n",
        "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-8)\n",
        "\n",
        "        # Compute policy loss\n",
        "        policy_loss = []\n",
        "        for log_prob, reward in zip(self.log_probs, rewards):\n",
        "            policy_loss.append(-log_prob * reward)\n",
        "\n",
        "        policy_loss = torch.stack(policy_loss).sum()\n",
        "\n",
        "        # Update\n",
        "        self.optimizer.zero_grad()\n",
        "        policy_loss.backward()\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Clear experience\n",
        "        self.log_probs.clear()\n",
        "        self.rewards.clear()\n",
        "\n",
        "def adaptive_masking_strategy(noisy_img, mask_prob, strategy='bernoulli'):\n",
        "    \"\"\"\n",
        "    Advanced masking strategies for Self2Self training with partial convolutions\n",
        "    \"\"\"\n",
        "    if strategy == 'bernoulli':\n",
        "        # Standard Bernoulli dropout\n",
        "        mask = (torch.rand_like(noisy_img) > mask_prob).float()\n",
        "\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "\n",
        "def self2self_train_pconv(model, noisy_img, mask_prob, num_iters=500, masking_strategy='bernoulli'):\n",
        "    \"\"\"\n",
        "    Self2Self training with Partial Convolution U-Net\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_iters)\n",
        "\n",
        "    losses = []\n",
        "\n",
        "    for iteration in range(num_iters):\n",
        "        # Generate mask for self-supervised training\n",
        "        self_mask = adaptive_masking_strategy(noisy_img, mask_prob, masking_strategy)\n",
        "\n",
        "        # Create input with masked regions\n",
        "        masked_input = noisy_img * self_mask\n",
        "\n",
        "        # Forward pass with partial convolution mask\n",
        "        # Use inverted self_mask as the partial conv mask (1 where data is valid)\n",
        "        pconv_mask = self_mask\n",
        "        output = model(masked_input, pconv_mask)\n",
        "\n",
        "        # Self2Self loss: predict masked pixels\n",
        "        loss = F.mse_loss(output * (1 - self_mask), noisy_img * (1 - self_mask))\n",
        "\n",
        "        # Add perceptual regularization in later iterations\n",
        "        if iteration > num_iters // 2:\n",
        "            # Encourage smoothness in homogeneous regions\n",
        "            smooth_loss = total_variation_loss(output)\n",
        "            loss += 0.01 * smooth_loss\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        if iteration % 100 == 0:\n",
        "            print(f\"  Iteration {iteration}, Loss: {loss.item():.6f}\")\n",
        "\n",
        "    return model, losses\n",
        "\n",
        "def total_variation_loss(img):\n",
        "    \"\"\"Total variation loss for smoothness regularization\"\"\"\n",
        "    batch_size, channels, h, w = img.size()\n",
        "    tv_h = torch.mean(torch.abs(img[:, :, 1:, :] - img[:, :, :-1, :]))\n",
        "    tv_w = torch.mean(torch.abs(img[:, :, :, 1:] - img[:, :, :, :-1]))\n",
        "    return tv_h + tv_w\n",
        "\n",
        "def self2self_inference_pconv(model, noisy_img, mask_prob, n_samples=10, masking_strategy='bernoulli'):\n",
        "    \"\"\"\n",
        "    Self2Self inference with Partial Convolution U-Net and multiple sampling\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for _ in range(n_samples):\n",
        "            # Generate different masks for each sample\n",
        "            self_mask = adaptive_masking_strategy(noisy_img, mask_prob, masking_strategy)\n",
        "            masked_input = noisy_img * self_mask\n",
        "\n",
        "            # Use the mask for partial convolution\n",
        "            pconv_mask = self_mask\n",
        "            output = model(masked_input, pconv_mask)\n",
        "            outputs.append(output)\n",
        "\n",
        "    # Average predictions\n",
        "    mean_output = torch.stack(outputs).mean(dim=0)\n",
        "\n",
        "    # Compute uncertainty (variance across samples)\n",
        "    uncertainty = torch.stack(outputs).var(dim=0).mean()\n",
        "\n",
        "    return mean_output, uncertainty.item()\n",
        "\n",
        "def s2srl_pconv_denoise(noisy_image_path, num_episodes=12, max_iterations_per_episode=400,\n",
        "                        quality_metrics=['paq2piq', 'niqe']):\n",
        "    \"\"\"\n",
        "    Main S2SRL-Denoise algorithm with Partial Convolution U-Net\n",
        "    Self-Supervised Reinforcement Learning for Single Image Denoising\n",
        "\n",
        "    Args:\n",
        "        noisy_image_path: Path to noisy input image\n",
        "        num_episodes: Number of RL episodes\n",
        "        max_iterations_per_episode: Training iterations per episode\n",
        "        quality_metrics: List of PyIQA metrics to use for quality assessment\n",
        "\n",
        "    Returns:\n",
        "        denoised_output: Denoised image tensor\n",
        "        results_dict: Dictionary containing training results and metrics\n",
        "    \"\"\"\n",
        "    print(\"=== S2SRL-Denoise with Partial Convolution U-Net ===\")\n",
        "    print(f\"Loading noisy image: {noisy_image_path}\")\n",
        "\n",
        "    # Load and preprocess image\n",
        "    try:\n",
        "        pil_img = Image.open(noisy_image_path).convert('RGB')\n",
        "        transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "        ])\n",
        "        noisy_tensor = transform(pil_img).unsqueeze(0).to(device)\n",
        "        print(f\"Image shape: {noisy_tensor.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # Initialize components\n",
        "    print(\"Initializing PyIQA quality assessment...\")\n",
        "    try:\n",
        "        quality_assessor = PyIQAQualityAssessment(metric_names=quality_metrics, device=device)\n",
        "    except Exception as e:\n",
        "        print(f\"Error initializing PyIQA: {e}\")\n",
        "        print(\"Please ensure pyiqa is installed: pip install pyiqa\")\n",
        "        return None, None\n",
        "\n",
        "    rl_agent = RLAgent(action_space_size=9, lr=0.02)\n",
        "\n",
        "    # Compute baseline quality (noisy image)\n",
        "    print(\"Computing baseline quality score...\")\n",
        "    baseline_score = quality_assessor.compute_score(noisy_tensor)\n",
        "    print(f\"Baseline quality score: {baseline_score:.4f}\")\n",
        "\n",
        "    best_score = -float('inf')\n",
        "    best_output = None\n",
        "    best_params = None\n",
        "\n",
        "    episode_scores = []\n",
        "    episode_params = []\n",
        "\n",
        "    print(f\"\\nStarting RL training for {num_episodes} episodes...\")\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        print(f\"\\n--- Episode {episode + 1}/{num_episodes} ---\")\n",
        "\n",
        "        # RL agent selects masking parameters\n",
        "        mask_prob, mask_strategy, action_idx = rl_agent.select_action()\n",
        "        print(f\"Selected mask probability: {mask_prob:.3f}, strategy: {mask_strategy}\")\n",
        "\n",
        "        # Initialize fresh Partial Convolution U-Net for this episode\n",
        "        denoiser = PartialConvUNet(in_channels=3, out_channels=3, base_features=48).to(device)\n",
        "\n",
        "        # Train denoiser with selected parameters\n",
        "        print(\"Training Partial Convolution U-Net denoiser...\")\n",
        "        trained_model, training_losses = self2self_train_pconv(\n",
        "            denoiser, noisy_tensor, mask_prob,\n",
        "            num_iters=max_iterations_per_episode,\n",
        "            masking_strategy=mask_strategy\n",
        "        )\n",
        "\n",
        "        # Generate denoised image\n",
        "        print(\"Generating denoised output...\")\n",
        "        denoised_output, uncertainty = self2self_inference_pconv(\n",
        "            trained_model, noisy_tensor, mask_prob,\n",
        "            n_samples=8, masking_strategy=mask_strategy\n",
        "        )\n",
        "\n",
        "        # Evaluate quality\n",
        "        print(\"Evaluating quality with PyIQA metrics...\")\n",
        "        quality_score = quality_assessor.compute_score(denoised_output)\n",
        "        improvement = quality_score - baseline_score\n",
        "\n",
        "        print(f\"Quality score: {quality_score:.4f} (improvement: {improvement:+.4f})\")\n",
        "        print(f\"Prediction uncertainty: {uncertainty:.6f}\")\n",
        "\n",
        "        # Store results\n",
        "        episode_scores.append(quality_score)\n",
        "        episode_params.append({\n",
        "            'mask_prob': mask_prob,\n",
        "            'mask_strategy': mask_strategy,\n",
        "            'quality_score': quality_score,\n",
        "            'uncertainty': uncertainty,\n",
        "            'training_loss': np.mean(training_losses[-10:])  # Average of last 10 losses\n",
        "        })\n",
        "\n",
        "        # Update best result\n",
        "        if quality_score > best_score:\n",
        "            best_score = quality_score\n",
        "            best_output = denoised_output.clone()\n",
        "            best_params = episode_params[-1].copy()\n",
        "            print(f\"*** New best score: {best_score:.4f} ***\")\n",
        "\n",
        "        # RL agent receives reward and updates policy\n",
        "        reward = improvement  # Reward based on improvement over baseline\n",
        "        rl_agent.rewards.append(reward)\n",
        "\n",
        "        # Update policy every 3 episodes\n",
        "        if (episode + 1) % 3 == 0:\n",
        "            print(\"Updating RL policy...\")\n",
        "            rl_agent.update_policy()\n",
        "\n",
        "    print(f\"\\n=== Training Complete ===\")\n",
        "    print(f\"Best quality score: {best_score:.4f}\")\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "    # Final refinement with best parameters\n",
        "    print(\"\\nPerforming final refinement...\")\n",
        "    final_denoiser = PartialConvUNet(in_channels=3, out_channels=3, base_features=48).to(device)\n",
        "    final_model, _ = self2self_train_pconv(\n",
        "        final_denoiser, noisy_tensor,\n",
        "        best_params['mask_prob'],\n",
        "        num_iters=600,\n",
        "        masking_strategy=best_params['mask_strategy']\n",
        "    )\n",
        "\n",
        "    final_output, final_uncertainty = self2self_inference_pconv(\n",
        "        final_model, noisy_tensor,\n",
        "        best_params['mask_prob'],\n",
        "        n_samples=15,\n",
        "        masking_strategy=best_params['mask_strategy']\n",
        "    )\n",
        "\n",
        "    print(\"Final quality assessment:\")\n",
        "    final_score = quality_assessor.compute_score(final_output)\n",
        "    print(f\"Final quality score: {final_score:.4f}\")\n",
        "\n",
        "    return final_output, {\n",
        "        'best_score': best_score,\n",
        "        'final_score': final_score,\n",
        "        'best_params': best_params,\n",
        "        'episode_scores': episode_scores,\n",
        "        'episode_params': episode_params,\n",
        "        'baseline_score': baseline_score\n",
        "    }\n",
        "\n",
        "def save_results(denoised_output, results_dict, output_path=\"denoised_pconv_output.png\"):\n",
        "    \"\"\"Save the denoised image and print summary\"\"\"\n",
        "    if denoised_output is not None:\n",
        "        # Save denoised image\n",
        "        denoised_pil = transforms.ToPILImage()(denoised_output.squeeze(0).cpu())\n",
        "        denoised_pil.save(output_path)\n",
        "        print(f\"Denoised image saved as: {output_path}\")\n",
        "\n",
        "        print(\"\\n=== Enhanced Algorithm Summary ===\")\n",
        "        print(\"S2SRL-Denoise with Partial Convolution U-Net combines:\")\n",
        "        print(\"1. Self2Self self-supervised learning\")\n",
        "        print(\"2. Partial Convolution U-Net architecture for better structure preservation\")\n",
        "        print(\"3. Reinforcement learning for masking strategy optimization\")\n",
        "        print(\"4. Professional PyIQA no-reference quality assessment\")\n",
        "        print(\"5. Advanced masking strategies (Bernoulli, Structured, Gradient-aware)\")\n",
        "        print(\"6. Multi-sample inference with uncertainty estimation\")\n",
        "        print(\"\\nThis creates a novel, fully self-supervised approach\")\n",
        "        print(\"with state-of-the-art partial convolution handling!\")\n",
        "\n",
        "\n",
        "        print(f\"\\nFinal Results:\")\n",
        "        print(f\"- Baseline score: {results_dict['baseline_score']:.4f}\")\n",
        "        print(f\"- Best score: {results_dict['best_score']:.4f}\")\n",
        "        print(f\"- Final score: {results_dict['final_score']:.4f}\")\n",
        "        print(f\"- Improvement: {results_dict['final_score'] - results_dict['baseline_score']:+.4f}\")\n",
        "        print(f\"- Best masking strategy: {results_dict['best_params']['mask_strategy']}\")\n",
        "        print(f\"- Best mask probability: {results_dict['best_params']['mask_prob']:.3f}\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with your actual noisy image path\n",
        "    noisy_image_path = \"path/to/your/noisy_image.png\"\n",
        "\n",
        "    print(\"Please provide the path to your noisy image.\")\n",
        "    print(\"Example usage:\")\n",
        "    print(\"noisy_image_path = 'your_noisy_image.jpg'\")\n",
        "    print(\"denoised_output, results = s2srl_pconv_denoise(noisy_image_path)\")\n",
        "    print(\"save_results(denoised_output, results)\")\n",
        "\n",
        "    # Example with custom parameters\n",
        "    # denoised_output, results = s2srl_pconv_denoise(\n",
        "    #     noisy_image_path,\n",
        "    #     num_episodes=15,\n",
        "    #     max_iterations_per_episode=400,\n",
        "    #     quality_metrics=['paq2piq', 'niqe', 'brisque', 'nima']  # Use multiple metrics\n",
        "    # )\n",
        "    #\n",
        "    # if denoised_output is not None:\n",
        "    #     save_results(denoised_output, results, \"my_pconv_denoised_image.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CobTd3HAfz_b",
        "outputId": "13521bb1-3ee7-467b-a605-9cc18b858a5f"
      },
      "outputs": [],
      "source": [
        "!pip install pyiqa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1OmrHRGgHe3",
        "outputId": "33cc75f3-45a6-4924-e31b-29331a6ff9a5"
      },
      "outputs": [],
      "source": [
        "# Advanced usage with more episodes and metrics\n",
        "denoised_output, results = s2srl_pconv_denoise(\n",
        "    \"036.png\",\n",
        "    num_episodes=5,\n",
        "    max_iterations_per_episode=800,\n",
        "    quality_metrics=['paq2piq', 'niqe', 'brisque', 'nima']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "HBEyrc92qYI9",
        "outputId": "086f04b1-03a8-4cfa-e92f-c28c2cfeb18b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(denoised_output.squeeze(0).permute(1, 2, 0).cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "vR0vAu2KqfkU",
        "outputId": "60214923-32f1-4cab-b21c-8a88e836959d"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convert and clip image to [0, 1] range\n",
        "image = denoised_output.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "image = np.clip(image, 0, 1)  # very important!\n",
        "\n",
        "# Display without axes\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()\n",
        "\n",
        "# Save the image with clipping and no color distortion\n",
        "plt.imsave('denoised_image.png', image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z60NLnRzuFq",
        "outputId": "92c434c6-454c-49f7-c7c3-f1ef5ba09d1a"
      },
      "outputs": [],
      "source": [
        "# Enhanced S2SRL-Denoise with PyIQA Quality Loss Integration\n",
        "# Combining Self2Self+ with Direct PyIQA Loss Optimization and RL\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "class PyIQAQualityLoss:\n",
        "    \"\"\"\n",
        "    Enhanced Composite Normalized No-Reference IQA Loss for self-supervised denoising.\n",
        "    Includes adaptive weighting and gradient-aware loss computation.\n",
        "    \"\"\"\n",
        "    def __init__(self, metric_names=['paq2piq', 'niqe', 'brisque', 'nima'], device=None):\n",
        "        import pyiqa\n",
        "        self.device = device if device else torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.metrics = {}\n",
        "        self.metric_names = metric_names\n",
        "\n",
        "        # Enhanced normalization parameters based on empirical data\n",
        "        self.norm_params = {\n",
        "            'brisque': (0, 100, 'lower'),    # lower is better\n",
        "            'niqe': (0, 20, 'lower'),        # lower is better\n",
        "            'nima': (1, 10, 'higher'),       # higher is better\n",
        "            'paq2piq': (0, 100, 'higher'),  # higher is better (0-100 scale)\n",
        "            'musiq': (0, 100, 'higher'),     # higher is better\n",
        "            'dbcnn': (0, 100, 'higher'),     # higher is better\n",
        "        }\n",
        "\n",
        "        # Adaptive weights - can be learned or adjusted\n",
        "        self.base_weights = {\n",
        "            'brisque': 1.0,\n",
        "            'niqe': 1.0,\n",
        "            'nima': 0.5,\n",
        "            'paq2piq': 0.8,\n",
        "            'musiq': 0.6,\n",
        "            'dbcnn': 0.4,\n",
        "        }\n",
        "\n",
        "        print(\"Initializing Enhanced PyIQA metrics...\")\n",
        "        for name in metric_names:\n",
        "            try:\n",
        "                self.metrics[name] = pyiqa.create_metric(name, device=self.device)\n",
        "                print(f\"✓ Loaded {name}\")\n",
        "            except Exception as e:\n",
        "                print(f\"✗ Failed to load {name}: {e}\")\n",
        "\n",
        "        if not self.metrics:\n",
        "            raise RuntimeError(\"No metrics loaded. Check PyIQA installation.\")\n",
        "\n",
        "    def tv_loss(self, img):\n",
        "        \"\"\"Anisotropic Total Variation Loss for edge-preserving smoothness\"\"\"\n",
        "        # Horizontal and vertical differences\n",
        "        tv_h = torch.mean(torch.abs(img[:, :, :, :-1] - img[:, :, :, 1:]))\n",
        "        tv_w = torch.mean(torch.abs(img[:, :, :-1, :] - img[:, :, 1:, :]))\n",
        "        return tv_h + tv_w\n",
        "\n",
        "    def edge_preserving_loss(self, img):\n",
        "        \"\"\"Edge-preserving regularization using gradient magnitude\"\"\"\n",
        "        # Sobel-like edge detection\n",
        "        sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32, device=img.device).view(1, 1, 3, 3)\n",
        "        sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32, device=img.device).view(1, 1, 3, 3)\n",
        "\n",
        "        # Apply to each channel\n",
        "        grad_x = F.conv2d(img.mean(dim=1, keepdim=True), sobel_x, padding=1)\n",
        "        grad_y = F.conv2d(img.mean(dim=1, keepdim=True), sobel_y, padding=1)\n",
        "\n",
        "        # Gradient magnitude\n",
        "        grad_mag = torch.sqrt(grad_x**2 + grad_y**2 + 1e-8)\n",
        "\n",
        "        # Encourage smoothness in low-gradient regions, preserve high-gradient regions\n",
        "        return torch.mean(grad_mag * torch.exp(-grad_mag))\n",
        "\n",
        "    def compute_loss(self, img_tensor, use_tv=True, tv_weight=0.001,\n",
        "                     use_edge_preserving=True, edge_weight=0.0005,\n",
        "                     adaptive_weighting=True):\n",
        "        \"\"\"\n",
        "        Compute comprehensive quality loss with multiple regularization terms\n",
        "\n",
        "        Args:\n",
        "            img_tensor: Input image tensor [B, C, H, W] or [C, H, W]\n",
        "            use_tv: Whether to include Total Variation regularization\n",
        "            tv_weight: Weight for TV loss\n",
        "            use_edge_preserving: Whether to include edge-preserving regularization\n",
        "            edge_weight: Weight for edge-preserving loss\n",
        "            adaptive_weighting: Whether to use adaptive metric weighting\n",
        "        \"\"\"\n",
        "        # Ensure proper tensor format\n",
        "        if img_tensor.dim() == 3:\n",
        "            img_tensor = img_tensor.unsqueeze(0)\n",
        "        img_tensor = torch.clamp(img_tensor, 0, 1)\n",
        "\n",
        "        # Compute IQA scores\n",
        "        scores = {}\n",
        "        gradients = {}  # Store gradients for adaptive weighting\n",
        "\n",
        "        for name, metric in self.metrics.items():\n",
        "            try:\n",
        "                # Enable gradient computation for the metric\n",
        "                img_for_metric = img_tensor.clone().requires_grad_(True)\n",
        "                score = metric(img_for_metric)\n",
        "\n",
        "                if isinstance(score, torch.Tensor):\n",
        "                    score_value = score.item()\n",
        "                    # Compute gradient for adaptive weighting\n",
        "                    if adaptive_weighting and img_for_metric.grad is not None:\n",
        "                        grad_norm = torch.norm(img_for_metric.grad).item()\n",
        "                        gradients[name] = grad_norm\n",
        "                else:\n",
        "                    score_value = score\n",
        "                    gradients[name] = 1.0  # Default gradient norm\n",
        "\n",
        "                scores[name] = score_value\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"[!] Error computing {name}: {e}\")\n",
        "                scores[name] = 0.0\n",
        "                gradients[name] = 1.0\n",
        "\n",
        "        # Compute normalized loss components\n",
        "        total_loss = 0.0\n",
        "        total_weight = 0.0\n",
        "\n",
        "        for name, value in scores.items():\n",
        "            if name not in self.norm_params:\n",
        "                continue\n",
        "\n",
        "            min_val, max_val, direction = self.norm_params[name]\n",
        "\n",
        "            # Normalize score to [0, 1] range\n",
        "            if direction == 'higher':\n",
        "                # For \"higher is better\" metrics, invert the score\n",
        "                norm_score = (max_val - value) / (max_val - min_val + 1e-8)\n",
        "            else:\n",
        "                # For \"lower is better\" metrics, use as-is\n",
        "                norm_score = (value - min_val) / (max_val - min_val + 1e-8)\n",
        "\n",
        "            # Clamp to [0, 1]\n",
        "            norm_score = max(0.0, min(1.0, norm_score))\n",
        "\n",
        "            # Adaptive weighting based on gradient information\n",
        "            if adaptive_weighting:\n",
        "                # Higher gradient norm indicates more sensitivity -> higher weight\n",
        "                adaptive_factor = 1.0 + 0.5 * gradients.get(name, 1.0)\n",
        "                weight = self.base_weights.get(name, 1.0) * adaptive_factor\n",
        "            else:\n",
        "                weight = self.base_weights.get(name, 1.0)\n",
        "\n",
        "            total_loss += weight * norm_score\n",
        "            total_weight += weight\n",
        "\n",
        "        # Normalize by total weight\n",
        "        if total_weight > 0:\n",
        "            total_loss /= total_weight\n",
        "\n",
        "        # Add regularization terms\n",
        "        regularization_loss = 0.0\n",
        "\n",
        "        if use_tv:\n",
        "            tv_component = self.tv_loss(img_tensor)\n",
        "            regularization_loss += tv_weight * tv_component\n",
        "\n",
        "        if use_edge_preserving:\n",
        "            edge_component = self.edge_preserving_loss(img_tensor)\n",
        "            regularization_loss += edge_weight * edge_component\n",
        "\n",
        "        total_loss += regularization_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "class HybridLoss:\n",
        "    \"\"\"\n",
        "    Hybrid training loss combining Self2Self reconstruction with PyIQA quality loss\n",
        "    \"\"\"\n",
        "    def __init__(self, quality_loss_fn, recon_weight=1.0, quality_weight=0.1,\n",
        "                 adaptive_scheduling=True):\n",
        "        self.quality_loss_fn = quality_loss_fn\n",
        "        self.recon_weight = recon_weight\n",
        "        self.quality_weight = quality_weight\n",
        "        self.adaptive_scheduling = adaptive_scheduling\n",
        "        self.iteration = 0\n",
        "\n",
        "    def compute_loss(self, output, target, mask):\n",
        "        \"\"\"\n",
        "        Compute hybrid loss combining reconstruction and quality components\n",
        "\n",
        "        Args:\n",
        "            output: Model output [B, C, H, W]\n",
        "            target: Target image (noisy input) [B, C, H, W]\n",
        "            mask: Self2Self mask [B, C, H, W]\n",
        "        \"\"\"\n",
        "        self.iteration += 1\n",
        "\n",
        "        # Self2Self reconstruction loss (predict masked pixels)\n",
        "        recon_loss = F.mse_loss(output * (1 - mask), target * (1 - mask))\n",
        "\n",
        "        # PyIQA quality loss on the full output\n",
        "        quality_loss = self.quality_loss_fn.compute_loss(output)\n",
        "\n",
        "        # Adaptive scheduling: start with more reconstruction focus, gradually increase quality focus\n",
        "        if self.adaptive_scheduling:\n",
        "            # Sigmoid scheduling: quality weight increases over time\n",
        "            progress = min(self.iteration / 1000.0, 1.0)  # Normalize to [0, 1] over 1000 iterations\n",
        "            quality_factor = 1.0 / (1.0 + np.exp(-10 * (progress - 0.5)))  # Sigmoid curve\n",
        "            effective_quality_weight = self.quality_weight * quality_factor\n",
        "        else:\n",
        "            effective_quality_weight = self.quality_weight\n",
        "\n",
        "        # Combine losses\n",
        "        total_loss = self.recon_weight * recon_loss + effective_quality_weight * quality_loss\n",
        "\n",
        "        return total_loss, {\n",
        "            'recon_loss': recon_loss.item(),\n",
        "            'quality_loss': quality_loss,\n",
        "            'effective_quality_weight': effective_quality_weight,\n",
        "            'total_loss': total_loss.item()\n",
        "        }\n",
        "\n",
        "def enhanced_self2self_train_pconv(model, noisy_img, mask_prob, num_iters=500,\n",
        "                                   masking_strategy='bernoulli', use_hybrid_loss=True,\n",
        "                                   quality_metrics=['paq2piq', 'niqe', 'brisque']):\n",
        "    \"\"\"\n",
        "    Enhanced Self2Self training with PyIQA quality loss integration\n",
        "    \"\"\"\n",
        "    model.train()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_iters)\n",
        "\n",
        "    # Initialize hybrid loss if requested\n",
        "    if use_hybrid_loss:\n",
        "        quality_loss_fn = PyIQAQualityLoss(metric_names=quality_metrics, device=device)\n",
        "        hybrid_loss_fn = HybridLoss(quality_loss_fn, recon_weight=1.0, quality_weight=0.1)\n",
        "\n",
        "    losses = []\n",
        "    loss_components = []\n",
        "\n",
        "    for iteration in range(num_iters):\n",
        "        # Generate mask for self-supervised training\n",
        "        self_mask = adaptive_masking_strategy(noisy_img, mask_prob, masking_strategy)\n",
        "\n",
        "        # Create input with masked regions\n",
        "        masked_input = noisy_img * self_mask\n",
        "\n",
        "        # Forward pass\n",
        "        pconv_mask = self_mask\n",
        "        output = model(masked_input, pconv_mask)\n",
        "\n",
        "        if use_hybrid_loss:\n",
        "            # Use hybrid loss combining reconstruction and quality\n",
        "            loss, loss_dict = hybrid_loss_fn.compute_loss(output, noisy_img, self_mask)\n",
        "            loss_components.append(loss_dict)\n",
        "        else:\n",
        "            # Standard Self2Self loss only\n",
        "            loss = F.mse_loss(output * (1 - self_mask), noisy_img * (1 - self_mask))\n",
        "            loss_components.append({'recon_loss': loss.item(), 'quality_loss': 0.0})\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        if iteration % 100 == 0:\n",
        "            if use_hybrid_loss:\n",
        "                print(f\"  Iter {iteration}: Total={loss.item():.6f}, \"\n",
        "                      f\"Recon={loss_components[-1]['recon_loss']:.6f}, \"\n",
        "                      f\"Quality={loss_components[-1]['quality_loss']:.6f}\")\n",
        "            else:\n",
        "                print(f\"  Iter {iteration}: Loss={loss.item():.6f}\")\n",
        "\n",
        "    return model, losses, loss_components\n",
        "\n",
        "def adaptive_masking_strategy(noisy_img, mask_prob, strategy='bernoulli'):\n",
        "    \"\"\"Advanced masking strategies for Self2Self training\"\"\"\n",
        "    if strategy == 'bernoulli':\n",
        "        mask = (torch.rand_like(noisy_img) > mask_prob).float()\n",
        "    elif strategy == 'structured':\n",
        "        # Structured masking with random rectangles\n",
        "        mask = torch.ones_like(noisy_img)\n",
        "        b, c, h, w = noisy_img.shape\n",
        "        for _ in range(int(mask_prob * 20)):  # Number of rectangles\n",
        "            x1, y1 = np.random.randint(0, w-10), np.random.randint(0, h-10)\n",
        "            x2, y2 = min(x1 + np.random.randint(5, 15), w), min(y1 + np.random.randint(5, 15), h)\n",
        "            mask[:, :, y1:y2, x1:x2] = 0\n",
        "    else:  # fallback to bernoulli\n",
        "        mask = (torch.rand_like(noisy_img) > mask_prob).float()\n",
        "\n",
        "    return mask\n",
        "\n",
        "# Include the PartialConv2d, PConvBNReLU, ConvBNReLU, and PartialConvUNet classes from the original code\n",
        "# [Classes would be copied here - omitted for brevity but should be included]\n",
        "\n",
        "def enhanced_s2srl_pconv_denoise(noisy_image_path, num_episodes=12, max_iterations_per_episode=400,\n",
        "                                quality_metrics=['paq2piq', 'niqe', 'brisque'],\n",
        "                                use_hybrid_loss=True):\n",
        "    \"\"\"\n",
        "    Enhanced S2SRL-Denoise with PyIQA Quality Loss Integration\n",
        "\n",
        "    Args:\n",
        "        noisy_image_path: Path to noisy input image\n",
        "        num_episodes: Number of RL episodes\n",
        "        max_iterations_per_episode: Training iterations per episode\n",
        "        quality_metrics: List of PyIQA metrics for quality assessment\n",
        "        use_hybrid_loss: Whether to use hybrid loss (reconstruction + quality)\n",
        "\n",
        "    Returns:\n",
        "        denoised_output: Denoised image tensor\n",
        "        results_dict: Dictionary containing training results and metrics\n",
        "    \"\"\"\n",
        "    print(\"=== Enhanced S2SRL-Denoise with PyIQA Quality Loss ===\")\n",
        "    print(f\"Hybrid loss enabled: {use_hybrid_loss}\")\n",
        "\n",
        "    # Load and preprocess image\n",
        "    try:\n",
        "        pil_img = Image.open(noisy_image_path).convert('RGB')\n",
        "        transform = transforms.Compose([transforms.ToTensor()])\n",
        "        noisy_tensor = transform(pil_img).unsqueeze(0).to(device)\n",
        "        print(f\"Image shape: {noisy_tensor.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        return None, None\n",
        "\n",
        "    # Initialize quality assessor for RL rewards\n",
        "    quality_assessor = PyIQAQualityLoss(metric_names=quality_metrics, device=device)\n",
        "\n",
        "    # Initialize RL agent\n",
        "    from copy import deepcopy\n",
        "\n",
        "    class RLAgent:\n",
        "        def __init__(self, action_space_size=9, lr=0.02):\n",
        "            self.action_space_size = action_space_size\n",
        "            self.mask_probs = [0.2, 0.5, 0.8]\n",
        "            self.mask_strategies = ['bernoulli', 'bernoulli', 'bernoulli']\n",
        "            self.actions = [(p, s) for p in self.mask_probs for s in self.mask_strategies]\n",
        "\n",
        "            self.policy_logits = torch.zeros(action_space_size, requires_grad=True, device=device)\n",
        "            self.optimizer = optim.Adam([self.policy_logits], lr=lr)\n",
        "\n",
        "            self.log_probs = []\n",
        "            self.rewards = []\n",
        "\n",
        "        def select_action(self):\n",
        "            probs = torch.softmax(self.policy_logits, dim=0)\n",
        "            m = torch.distributions.Categorical(probs)\n",
        "            action = m.sample()\n",
        "            self.log_probs.append(m.log_prob(action))\n",
        "            mask_prob, mask_strategy = self.actions[action.item()]\n",
        "            return mask_prob, mask_strategy, action.item()\n",
        "\n",
        "        def update_policy(self):\n",
        "            if len(self.rewards) == 0:\n",
        "                return\n",
        "\n",
        "            rewards = torch.tensor(self.rewards, device=device)\n",
        "            rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-8)\n",
        "\n",
        "            policy_loss = []\n",
        "            for log_prob, reward in zip(self.log_probs, rewards):\n",
        "                policy_loss.append(-log_prob * reward)\n",
        "\n",
        "            policy_loss = torch.stack(policy_loss).sum()\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            policy_loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "            self.log_probs.clear()\n",
        "            self.rewards.clear()\n",
        "\n",
        "    rl_agent = RLAgent(action_space_size=9, lr=0.02)\n",
        "\n",
        "    # Compute baseline quality\n",
        "    baseline_score = quality_assessor.compute_loss(noisy_tensor)\n",
        "    print(f\"Baseline quality loss: {baseline_score:.4f}\")\n",
        "\n",
        "    best_score = float('inf')  # Lower is better for loss\n",
        "    best_output = None\n",
        "    best_params = None\n",
        "\n",
        "    episode_scores = []\n",
        "    episode_params = []\n",
        "\n",
        "    print(f\"\\nStarting enhanced RL training for {num_episodes} episodes...\")\n",
        "\n",
        "    for episode in range(num_episodes):\n",
        "        print(f\"\\n--- Episode {episode + 1}/{num_episodes} ---\")\n",
        "\n",
        "        # RL agent selects parameters\n",
        "        mask_prob, mask_strategy, action_idx = rl_agent.select_action()\n",
        "        print(f\"Selected mask probability: {mask_prob:.3f}, strategy: {mask_strategy}\")\n",
        "\n",
        "        # Initialize fresh model\n",
        "        from copy import deepcopy\n",
        "        # Assuming PartialConvUNet class is available\n",
        "        denoiser = PartialConvUNet(in_channels=3, out_channels=3, base_features=48).to(device)\n",
        "\n",
        "        # Train with enhanced loss\n",
        "        print(\"Training with enhanced PyIQA quality loss...\")\n",
        "        trained_model, training_losses, loss_components = enhanced_self2self_train_pconv(\n",
        "            denoiser, noisy_tensor, mask_prob,\n",
        "            num_iters=max_iterations_per_episode,\n",
        "            masking_strategy=mask_strategy,\n",
        "            use_hybrid_loss=use_hybrid_loss,\n",
        "            quality_metrics=quality_metrics\n",
        "        )\n",
        "\n",
        "        # Generate denoised output\n",
        "        print(\"Generating denoised output...\")\n",
        "        # Assuming self2self_inference_pconv function is available\n",
        "        denoised_output, uncertainty = self2self_inference_pconv(\n",
        "            trained_model, noisy_tensor, mask_prob,\n",
        "            n_samples=8, masking_strategy=mask_strategy\n",
        "        )\n",
        "\n",
        "        # Evaluate quality (lower loss is better)\n",
        "        quality_score = quality_assessor.compute_loss(denoised_output)\n",
        "        improvement = baseline_score - quality_score  # Positive is better\n",
        "\n",
        "        print(f\"Quality loss: {quality_score:.4f} (improvement: {improvement:+.4f})\")\n",
        "        print(f\"Prediction uncertainty: {uncertainty:.6f}\")\n",
        "\n",
        "        # Store results\n",
        "        episode_scores.append(quality_score)\n",
        "        episode_params.append({\n",
        "            'mask_prob': mask_prob,\n",
        "            'mask_strategy': mask_strategy,\n",
        "            'quality_score': quality_score,\n",
        "            'uncertainty': uncertainty,\n",
        "            'avg_training_loss': np.mean(training_losses[-10:])\n",
        "        })\n",
        "\n",
        "        # Update best result (lower loss is better)\n",
        "        if quality_score < best_score:\n",
        "            best_score = quality_score\n",
        "            best_output = denoised_output.clone()\n",
        "            best_params = episode_params[-1].copy()\n",
        "            print(f\"*** New best score: {best_score:.4f} ***\")\n",
        "\n",
        "        # RL reward\n",
        "        reward = improvement\n",
        "        rl_agent.rewards.append(reward)\n",
        "\n",
        "        # Update policy\n",
        "        if (episode + 1) % 3 == 0:\n",
        "            print(\"Updating RL policy...\")\n",
        "            rl_agent.update_policy()\n",
        "\n",
        "    print(f\"\\n=== Enhanced Training Complete ===\")\n",
        "    print(f\"Best quality loss: {best_score:.4f}\")\n",
        "    print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "    return best_output, {\n",
        "        'best_score': best_score,\n",
        "        'best_params': best_params,\n",
        "        'episode_scores': episode_scores,\n",
        "        'episode_params': episode_params,\n",
        "        'baseline_score': baseline_score,\n",
        "        'improvement': baseline_score - best_score\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Enhanced S2SRL-Denoise with PyIQA Quality Loss Integration\")\n",
        "    print(\"Key improvements:\")\n",
        "    print(\"1. Direct PyIQA loss optimization during training\")\n",
        "    print(\"2. Hybrid loss combining reconstruction + quality\")\n",
        "    print(\"3. Adaptive loss scheduling\")\n",
        "    print(\"4. Enhanced regularization (TV + edge-preserving)\")\n",
        "    print(\"5. Gradient-aware adaptive metric weighting\")\n",
        "\n",
        "    # noisy_image_path = \"path/to/your/noisy_image.jpg\"\n",
        "    # denoised_output, results = enhanced_s2srl_pconv_denoise(\n",
        "    #     noisy_image_path,\n",
        "    #     num_episodes=15,\n",
        "    #     max_iterations_per_episode=400,\n",
        "    #     quality_metrics=['paq2piq', 'niqe', 'brisque', 'nima'],\n",
        "    #     use_hybrid_loss=True\n",
        "    # )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW6ROhGTzv5Q",
        "outputId": "d2408e5b-c9b0-453c-f587-eff43b28c2cd"
      },
      "outputs": [],
      "source": [
        "denoised_output, results = enhanced_s2srl_pconv_denoise(\n",
        "         \"036.png\",\n",
        "         num_episodes=10,\n",
        "         max_iterations_per_episode=800,\n",
        "         quality_metrics=['paq2piq', 'niqe', 'brisque', 'nima'],\n",
        "         use_hybrid_loss=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "zCssNBxc4QJd",
        "outputId": "8c5e7f56-dd17-48c7-bbe0-681740d50de7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(denoised_output.squeeze(0).permute(1, 2, 0).cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "id": "ZzMty6-r4a4i",
        "outputId": "3435f557-0d3c-4f7b-994a-eaf38c8448f2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Convert and clip image to [0, 1] range\n",
        "image = denoised_output.squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "image = np.clip(image, 0, 1)  # very important!\n",
        "\n",
        "# Display without axes\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(image)\n",
        "plt.axis('off')\n",
        "plt.tight_layout(pad=0)\n",
        "plt.show()\n",
        "\n",
        "# Save the image with clipping and no color distortion\n",
        "plt.imsave('denoised_image.png', image)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

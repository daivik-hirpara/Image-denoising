{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "290SpHLBMUzL",
        "outputId": "45fa4114-f38b-4ea8-ab12-7cb7463e15f4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "=== Noise2Self Single-Shot RGB Image Denoising ===\n",
            "\n",
            "Image shape: torch.Size([3, 512, 512])\n",
            "Image dtype: torch.float32\n",
            "Image range: [0.000, 1.000]\n",
            "Starting Noise2Self training...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|▌         | 1/20 [01:51<35:10, 111.07s/it]"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/20, Loss: 0.002282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 16/20 [29:19<07:07, 106.82s/it]"
          ]
        }
      ],
      "source": [
        "# Noise2Self Single-Shot RGB Image Denoising\n",
        "# This notebook implements the Noise2Self algorithm for denoising a single 512x512 RGB image\n",
        "# Based on: \"Noise2Self: Blind Denoising by Self-Supervision\" (Batson & Royer, 2019)\n",
        "\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "class Masker:\n",
        "    \"\"\"\n",
        "    Noise2Self masker that randomly masks pixels during training\n",
        "    \"\"\"\n",
        "    def __init__(self, mask_ratio=0.5):\n",
        "        self.mask_ratio = mask_ratio\n",
        "\n",
        "    def mask(self, images, step):\n",
        "        \"\"\"\n",
        "        Randomly mask pixels in the input images\n",
        "        Args:\n",
        "            images: Input tensor of shape (B, C, H, W)\n",
        "            step: Current training step (used for reproducible masking)\n",
        "        Returns:\n",
        "            masked_input: Input with some pixels set to 0\n",
        "            mask: Binary mask indicating which pixels to predict\n",
        "        \"\"\"\n",
        "        # Set random seed based on step for reproducible masking\n",
        "        torch.manual_seed(step)\n",
        "\n",
        "        B, C, H, W = images.shape\n",
        "        mask = torch.rand(B, 1, H, W, device=images.device) < self.mask_ratio\n",
        "\n",
        "        # Create masked input by setting masked pixels to 0\n",
        "        masked_input = images.clone()\n",
        "        masked_input = masked_input * (~mask).float()\n",
        "\n",
        "        # Expand mask to match number of channels\n",
        "        mask = mask.expand(-1, C, -1, -1)\n",
        "\n",
        "        return masked_input, mask\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Simple U-Net architecture for image denoising\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3, out_channels=3):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        # Encoder\n",
        "        self.enc1 = self.conv_block(in_channels, 64)\n",
        "        self.enc2 = self.conv_block(64, 128)\n",
        "        self.enc3 = self.conv_block(128, 256)\n",
        "        self.enc4 = self.conv_block(256, 512)\n",
        "\n",
        "        # Bottleneck\n",
        "        self.bottleneck = self.conv_block(512, 1024)\n",
        "\n",
        "        # Decoder\n",
        "        self.upconv4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)\n",
        "        self.dec4 = self.conv_block(1024, 512)\n",
        "\n",
        "        self.upconv3 = nn.ConvTranspose2d(512, 256, 2, stride=2)\n",
        "        self.dec3 = self.conv_block(512, 256)\n",
        "\n",
        "        self.upconv2 = nn.ConvTranspose2d(256, 128, 2, stride=2)\n",
        "        self.dec2 = self.conv_block(256, 128)\n",
        "\n",
        "        self.upconv1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
        "        self.dec1 = self.conv_block(128, 64)\n",
        "\n",
        "        # Output layer\n",
        "        self.out_conv = nn.Conv2d(64, out_channels, 1)\n",
        "\n",
        "        # Pooling\n",
        "        self.pool = nn.MaxPool2d(2)\n",
        "\n",
        "    def conv_block(self, in_channels, out_channels):\n",
        "        \"\"\"Convolutional block with two conv layers\"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        e1 = self.enc1(x)\n",
        "        e2 = self.enc2(self.pool(e1))\n",
        "        e3 = self.enc3(self.pool(e2))\n",
        "        e4 = self.enc4(self.pool(e3))\n",
        "\n",
        "        # Bottleneck\n",
        "        b = self.bottleneck(self.pool(e4))\n",
        "\n",
        "        # Decoder\n",
        "        d4 = self.upconv4(b)\n",
        "        d4 = torch.cat([d4, e4], dim=1)\n",
        "        d4 = self.dec4(d4)\n",
        "\n",
        "        d3 = self.upconv3(d4)\n",
        "        d3 = torch.cat([d3, e3], dim=1)\n",
        "        d3 = self.dec3(d3)\n",
        "\n",
        "        d2 = self.upconv2(d3)\n",
        "        d2 = torch.cat([d2, e2], dim=1)\n",
        "        d2 = self.dec2(d2)\n",
        "\n",
        "        d1 = self.upconv1(d2)\n",
        "        d1 = torch.cat([d1, e1], dim=1)\n",
        "        d1 = self.dec1(d1)\n",
        "\n",
        "        # Output\n",
        "        out = self.out_conv(d1)\n",
        "        return out\n",
        "\n",
        "class SingleImageDataset(Dataset):\n",
        "    \"\"\"Dataset for single image training\"\"\"\n",
        "    def __init__(self, image_tensor, num_samples=1000):\n",
        "        # Ensure image has batch dimension\n",
        "        if len(image_tensor.shape) == 3:\n",
        "            self.image = image_tensor.unsqueeze(0)  # Add batch dimension\n",
        "        else:\n",
        "            self.image = image_tensor\n",
        "        self.num_samples = num_samples\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_samples\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.image.squeeze(0), self.image.squeeze(0)  # Return without batch dim for DataLoader\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    \"\"\"Load and preprocess RGB image to 512x512\"\"\"\n",
        "    # If no image path provided, create a synthetic noisy image for demo\n",
        "    if image_path is None:\n",
        "        print(\"No image provided. Creating synthetic noisy image for demonstration...\")\n",
        "        # Create a synthetic clean image (gradient + patterns)\n",
        "        x = np.linspace(0, 1, 512)\n",
        "        y = np.linspace(0, 1, 512)\n",
        "        X, Y = np.meshgrid(x, y)\n",
        "\n",
        "        # Create RGB channels with different patterns\n",
        "        clean_r = 0.5 + 0.3 * np.sin(10 * X) * np.cos(10 * Y)\n",
        "        clean_g = 0.5 + 0.3 * np.cos(8 * X) * np.sin(12 * Y)\n",
        "        clean_b = 0.5 + 0.3 * np.sin(6 * X + 2) * np.cos(8 * Y + 1)\n",
        "\n",
        "        clean_image = np.stack([clean_r, clean_g, clean_b], axis=2)\n",
        "        clean_image = np.clip(clean_image, 0, 1)\n",
        "\n",
        "        # Add Gaussian noise\n",
        "        noise_std = 0.1\n",
        "        noisy_image = clean_image + np.random.normal(0, noise_std, clean_image.shape)\n",
        "        noisy_image = np.clip(noisy_image, 0, 1)\n",
        "\n",
        "        return torch.tensor(noisy_image, dtype=torch.float32).permute(2, 0, 1), clean_image\n",
        "\n",
        "    else:\n",
        "        # Load real image\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "        # Resize to 512x512\n",
        "        transform = transforms.Compose([\n",
        "            transforms.Resize((512, 512)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "\n",
        "        image_tensor = transform(image)\n",
        "        return image_tensor, None\n",
        "\n",
        "def train_noise2self(noisy_image, num_epochs=50, learning_rate=0.001):\n",
        "    \"\"\"Train Noise2Self model on single noisy image\"\"\"\n",
        "\n",
        "    # Create model\n",
        "    model = UNet(in_channels=3, out_channels=3).to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.MSELoss()\n",
        "    masker = Masker(mask_ratio=0.5)\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    dataset = SingleImageDataset(noisy_image, num_samples=500)\n",
        "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    # Training loop\n",
        "    model.train()\n",
        "    losses = []\n",
        "\n",
        "    print(\"Starting Noise2Self training...\")\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        epoch_loss = 0\n",
        "\n",
        "        for step, (batch_images, _) in enumerate(dataloader):\n",
        "            # Ensure batch_images has correct shape [B, C, H, W]\n",
        "            if len(batch_images.shape) == 3:\n",
        "                batch_images = batch_images.unsqueeze(0)\n",
        "\n",
        "            batch_images = batch_images.to(device)\n",
        "\n",
        "            # Apply masking\n",
        "            masked_input, mask = masker.mask(batch_images, epoch * len(dataloader) + step)\n",
        "\n",
        "            # Forward pass\n",
        "            optimizer.zero_grad()\n",
        "            output = model(masked_input)\n",
        "\n",
        "            # Compute loss only on masked pixels\n",
        "            loss = criterion(output * mask.float(), batch_images * mask.float())\n",
        "\n",
        "            # Backward pass\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        avg_loss = epoch_loss / len(dataloader)\n",
        "        losses.append(avg_loss)\n",
        "\n",
        "        # Print progress every 200 epochs\n",
        "        if epoch % 200 == 0:\n",
        "            print(f\"Epoch {epoch}/{num_epochs}, Loss: {avg_loss:.6f}\")\n",
        "\n",
        "    return model, losses\n",
        "\n",
        "def denoise_image(model, noisy_image):\n",
        "    \"\"\"Apply trained model to denoise the image\"\"\"\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        noisy_input = noisy_image.unsqueeze(0).to(device)\n",
        "        denoised = model(noisy_input)\n",
        "        denoised = torch.clamp(denoised, 0, 1)\n",
        "        return denoised.squeeze(0).cpu()\n",
        "\n",
        "def visualize_results(noisy_image, denoised_image, clean_image=None, losses=None):\n",
        "    \"\"\"Visualize the denoising results\"\"\"\n",
        "\n",
        "    if clean_image is not None:\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "        # Convert tensors to numpy for visualization\n",
        "        noisy_np = noisy_image.permute(1, 2, 0).numpy()\n",
        "        denoised_np = denoised_image.permute(1, 2, 0).numpy()\n",
        "\n",
        "        # Top row: Full images\n",
        "        axes[0, 0].imshow(noisy_np)\n",
        "        axes[0, 0].set_title('Noisy Image')\n",
        "        axes[0, 0].axis('off')\n",
        "\n",
        "        axes[0, 1].imshow(denoised_np)\n",
        "        axes[0, 1].set_title('Denoised Image (Noise2Self)')\n",
        "        axes[0, 1].axis('off')\n",
        "\n",
        "        axes[0, 2].imshow(clean_image)\n",
        "        axes[0, 2].set_title('Clean Image (Ground Truth)')\n",
        "        axes[0, 2].axis('off')\n",
        "\n",
        "        # Bottom row: Crops for better detail view\n",
        "        crop_size = 128\n",
        "        start_x, start_y = 192, 192  # Center crop\n",
        "\n",
        "        noisy_crop = noisy_np[start_y:start_y+crop_size, start_x:start_x+crop_size]\n",
        "        denoised_crop = denoised_np[start_y:start_y+crop_size, start_x:start_x+crop_size]\n",
        "        clean_crop = clean_image[start_y:start_y+crop_size, start_x:start_x+crop_size]\n",
        "\n",
        "        axes[1, 0].imshow(noisy_crop)\n",
        "        axes[1, 0].set_title('Noisy (Crop)')\n",
        "        axes[1, 0].axis('off')\n",
        "\n",
        "        axes[1, 1].imshow(denoised_crop)\n",
        "        axes[1, 1].set_title('Denoised (Crop)')\n",
        "        axes[1, 1].axis('off')\n",
        "\n",
        "        axes[1, 2].imshow(clean_crop)\n",
        "        axes[1, 2].set_title('Clean (Crop)')\n",
        "        axes[1, 2].axis('off')\n",
        "\n",
        "    else:\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "        noisy_np = noisy_image.permute(1, 2, 0).numpy()\n",
        "        denoised_np = denoised_image.permute(1, 2, 0).numpy()\n",
        "\n",
        "        axes[0].imshow(noisy_np)\n",
        "        axes[0].set_title('Noisy Input Image')\n",
        "        axes[0].axis('off')\n",
        "\n",
        "        axes[1].imshow(denoised_np)\n",
        "        axes[1].set_title('Denoised Output (Noise2Self)')\n",
        "        axes[1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Plot training loss\n",
        "    if losses is not None:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.plot(losses)\n",
        "        plt.title('Training Loss (Noise2Self)')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('MSE Loss')\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "def calculate_metrics(clean_image, denoised_image):\n",
        "    \"\"\"Calculate PSNR and MSE metrics\"\"\"\n",
        "    if clean_image is None:\n",
        "        return None, None\n",
        "\n",
        "    clean_tensor = torch.tensor(clean_image, dtype=torch.float32).permute(2, 0, 1)\n",
        "\n",
        "    mse = torch.mean((clean_tensor - denoised_image) ** 2).item()\n",
        "    psnr = 20 * torch.log10(1.0 / torch.sqrt(torch.tensor(mse))).item()\n",
        "\n",
        "    return psnr, mse\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    print(\"=== Noise2Self Single-Shot RGB Image Denoising ===\\n\")\n",
        "\n",
        "    # Option 1: Use your own image (uncomment and provide path)\n",
        "    image_path = \"036.png\"\n",
        "    noisy_image, clean_image = load_and_preprocess_image(image_path)\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"Image shape: {noisy_image.shape}\")\n",
        "    print(f\"Image dtype: {noisy_image.dtype}\")\n",
        "    print(f\"Image range: [{noisy_image.min():.3f}, {noisy_image.max():.3f}]\")\n",
        "\n",
        "    # Train Noise2Self model\n",
        "    model, losses = train_noise2self(noisy_image, num_epochs=20, learning_rate=0.001)\n",
        "\n",
        "    # Denoise the image\n",
        "    print(\"\\nApplying denoising...\")\n",
        "    denoised_image = denoise_image(model, noisy_image)\n",
        "\n",
        "    # Calculate metrics if clean image is available\n",
        "    if clean_image is not None:\n",
        "        psnr, mse = calculate_metrics(clean_image, denoised_image)\n",
        "        print(f\"\\nDenoising Metrics:\")\n",
        "        print(f\"PSNR: {psnr:.2f} dB\")\n",
        "        print(f\"MSE: {mse:.6f}\")\n",
        "\n",
        "    # Visualize results\n",
        "    print(\"\\nVisualizing results...\")\n",
        "    visualize_results(noisy_image, denoised_image, clean_image, losses)\n",
        "\n",
        "    print(\"\\n=== Denoising Complete! ===\")\n",
        "\n",
        "    return model, noisy_image, denoised_image\n",
        "\n",
        "# Run the main function\n",
        "if __name__ == \"__main__\":\n",
        "    model, noisy_image, denoised_image = main()\n",
        "\n",
        "# Instructions for using your own image:\n",
        "print(\"\"\"\n",
        "To use your own noisy RGB image:\n",
        "\n",
        "1. Upload your image to Colab:\n",
        "   - Click on Files tab (folder icon) in the left sidebar\n",
        "   - Click Upload and select your image\n",
        "   - Copy the file path\n",
        "\n",
        "2. Modify the code:\n",
        "   - Uncomment the lines in main() function:\n",
        "     # image_path = \"/path/to/your/noisy/image.jpg\"\n",
        "     # noisy_image, clean_image = load_and_preprocess_image(image_path)\n",
        "   - Replace the path with your uploaded image path\n",
        "   - Comment out the synthetic image lines:\n",
        "     # image_path = None\n",
        "     # noisy_image, clean_image = load_and_preprocess_image(image_path)\n",
        "\n",
        "3. Re-run the notebook\n",
        "\n",
        "The algorithm will automatically:\n",
        "- Resize your image to 512x512\n",
        "- Train a U-Net using Noise2Self methodology\n",
        "- Output the denoised image\n",
        "\n",
        "Key parameters you can adjust:\n",
        "- num_epochs: More epochs = better denoising but longer training\n",
        "- learning_rate: Higher = faster training but might be unstable\n",
        "- mask_ratio in Masker: Fraction of pixels to mask during training\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_np = (denoised_image.clamp(0, 1).permute(1, 2, 0).numpy() * 255).astype(np.uint8)\n",
        "Image.fromarray(out_np).save('denoised_output.png')\n",
        "print(\"Saved denoised image to denoised_output.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0kmWnlxKWeI",
        "outputId": "79d35103-200a-4c00-a6ad-d91b644e9868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved denoised image to denoised_output.png\n"
          ]
        }
      ]
    }
  ]
}
